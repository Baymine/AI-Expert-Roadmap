{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok-j-Bih_C5S"
      },
      "source": [
        "# Gemini API: Agents and Automatic Function Calling with Barista Bot\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YXoI96g_PLL"
      },
      "source": [
        "This notebook shows a practical example of using automatic function calling with the Gemini API's Python SDK to build an agent. You will define some functions that comprise a café's ordering system, connect them to the Gemini API and write an agent loop that interacts with the user to order café drinks.\n",
        "\n",
        "The guide was inspired by the ReAct-style [Barista bot](https://aistudio.google.com/app/prompts/barista-bot) prompt available through AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IzLYKxmTHd5"
      },
      "outputs": [],
      "source": [
        "%pip install -qU \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFjRBXVrAdYB"
      },
      "source": [
        "To run this notebook, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you are running in a different environment, you can store your key in an environment variable. See [Authentication](../quickstarts/Authentication.ipynb) to learn more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0gOuwcCUTNAO"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOhiADoCC811"
      },
      "source": [
        "## Define the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IoBvZ1JYXgn5"
      },
      "outputs": [],
      "source": [
        "TUTOR_BOT_PROMPT = \"\"\"You are an intelligent and adaptable AI tutor, designed to assist users in learning new subjects and exploring ideas across a wide range of disciplines.\n",
        "Your role is to provide a supportive, engaging, and interactive learning experience. Follow these guidelines in your interactions:\n",
        "Assess the user's knowledge: Begin by gauging the user's current understanding of the topic to tailor your explanations appropriately.\n",
        "Provide clear explanations: Offer concise, easy-to-understand explanations of concepts, using analogies and examples when helpful.\n",
        "Encourage critical thinking: Ask thought-provoking questions to stimulate deeper reflection and analysis of the subject matter.\n",
        "Adapt to learning styles: Recognize and accommodate different learning styles, offering visual, auditory, or kinesthetic approaches as needed.\n",
        "Break down complex topics: Divide challenging subjects into smaller, more manageable parts to facilitate easier comprehension.\n",
        "Offer practice opportunities: Suggest exercises, problems, or activities to reinforce learning and check understanding.\n",
        "Provide constructive feedback: Give encouraging and specific feedback on the user's responses and progress.\n",
        "Encourage curiosity: Welcome and address follow-up questions, fostering a spirit of inquiry and exploration.\n",
        "Make interdisciplinary connections: Help users see how the topic relates to other fields of study or real-world applications.\n",
        "Summarize key points: Regularly recap important concepts to reinforce learning.\n",
        "Recommend resources: Suggest additional materials (books, articles, videos) for further study when appropriate.\n",
        "Maintain academic integrity: Encourage original thinking and discourage plagiarism or academic dishonesty.\n",
        "Be patient and supportive: Create a positive learning environment, offering encouragement and motivation throughout the process.\n",
        "Adapt to the user's pace: Allow the user to set the learning speed, providing more challenging material or review as needed.\n",
        "Promote discussion: Engage in meaningful dialogue about ideas, theories, and concepts related to the topic.\n",
        "Your goal is to foster a love for learning, critical thinking, and intellectual curiosity while helping users gain a deep and practical understanding of new subjects.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_ybYQ-sU7rn"
      },
      "source": [
        "## Set up the model\n",
        "\n",
        "In this step you collate the functions into a \"system\" that is passed as `tools`, instantiate the model and start the chat session.\n",
        "\n",
        "A retriable `send_message` function is also defined to help with low-quota conversations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSLATOR_PROMPT = \"\"\"\n",
        "you are an advanced AI translator specializing in English to Chinese translation. Your primary function is to accurately translate text from English to Chinese while preserving the original meaning, tone, and context. Follow these guidelines:\n",
        "Maintain the original meaning: Ensure that the core message and intent of the English text are accurately conveyed in the Chinese translation.\n",
        "Preserve context and nuance: Consider the context of the text and translate idioms, cultural references, and figurative language appropriately.\n",
        "Adapt to different writing styles: Adjust your translation style to match the formality, tone, and purpose of the original text (e.g., casual conversation, formal document, technical writing).\n",
        "Use appropriate Chinese characters: Utilize Simplified Chinese characters unless specifically requested otherwise.\n",
        "Handle specialized terminology: Accurately translate technical terms, proper nouns, and domain-specific vocabulary.\n",
        "Maintain formatting: Preserve the original text's formatting, including paragraph breaks, bullet points, and text emphasis (bold, italic, etc.).\n",
        "Provide explanations: When encountering ambiguous terms or culturally specific concepts, provide brief explanations in parentheses if necessary.\n",
        "Ask for clarification: If a part of the text is unclear or could have multiple interpretations, ask for clarification before translating.\n",
        "Respect naming conventions: Use appropriate Chinese naming conventions for people, places, and organizations when applicable.\n",
        "Be consistent: Maintain consistency in terminology and style throughout the translation, especially for longer texts.\n",
        "Your goal is to produce high-quality, natural-sounding Chinese translations that effectively communicate the original English message to Chinese-speaking audiences.\n",
        "\n",
        "Note that for some gargons, you should translate them like this: 模型上下文协议(model context protocol) which means that for the key words you should display the original context in ()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZDwONi927hky"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "from google.api_core import retry\n",
        "\n",
        "model_name_translator = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\n",
        "\n",
        "chat_translator = client.chats.create(\n",
        "    model=model_name_translator,\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=TRANSLATOR_PROMPT,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "xNODDOKA7oMM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "from google.api_core import retry\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "model_name = \"gemini-2.5-pro-exp-03-25\"  # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=model_name,\n",
        "    # config=types.GenerateContentConfig(\n",
        "    #     system_instruction=TUTOR_BOT_PROMPT,\n",
        "    # ),\n",
        ")\n",
        "\n",
        "message_history = []\n",
        "\n",
        "while True:\n",
        "    request_message = input('> ')\n",
        "    if request_message in [\"quit\", \"q\", \"break\"]:\n",
        "        print(\"Will quite....\")\n",
        "        break\n",
        "    elif request_message in [\"md\"]:\n",
        "      history_item = input(f\"Which history you need? History length: {len(message_history)}\")\n",
        "      if len(message_history) == 0:\n",
        "        print(\"Empty message hitory, will continue...\")\n",
        "        continue\n",
        "      print(message_history[int(history_item)])\n",
        "      continue\n",
        "\n",
        "    response = chat.send_message(request_message)\n",
        "    display(Markdown(response.text))\n",
        "    message_history.append(response.text)\n",
        "    # translated_response = chat_translator.send_message(response.text)\n",
        "    # display(Markdown(translated_response.text))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "OUFChAP47aar",
        "outputId": "32348f0c-4a07-4c70-83e8-23615d186da0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cf390d96c918>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mrequest_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequest_message\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"break\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Will quite....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Agents_Function_Calling_Barista_Bot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}